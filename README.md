# âœ‹ Rock, Paper, Scissors - Clasificador de gestos con MediaPipe + Keras

Este proyecto permite capturar gestos desde la cÃ¡mara web, entrenar un modelo de clasificaciÃ³n y luego predecir en tiempo real los gestos de **Piedra**, **Papel** y **Tijeras**.

Se usa **MediaPipe** para detectar los puntos clave de la mano, y una **red neuronal entrenada con Keras** para clasificar el gesto.

---

## ğŸ“ Estructura del proyecto

```
rock-paper-scissors/
â”œâ”€â”€ capturas/                     # Carpeta para imÃ¡genes guardadas durante la predicciÃ³n
â”œâ”€â”€ dataset.rar                   # ğŸ“¦ Dataset comprimido (ver nota abajo)
â”œâ”€â”€ record-dataset.py             # Script para grabar gestos y construir el dataset
â”œâ”€â”€ train-gesture-classifier.py   # Script para entrenar la red neuronal
â”œâ”€â”€ rock-paper-scissors.py        # Script para predecir el gesto en tiempo real
â”œâ”€â”€ rps_dataset.npy               # Coordenadas x,y de cada gesto
â”œâ”€â”€ rps_labels.npy                # Etiquetas correspondientes a los gestos
â”œâ”€â”€ rps_model.h5                  # Modelo entrenado guardado
â”œâ”€â”€ rps_scaler_mean.npy           # Media del escalador
â”œâ”€â”€ rps_scaler_scale.npy          # Escala del escalador
â”œâ”€â”€ requirements.txt              # Dependencias necesarias
â””â”€â”€ README.md                     # Este archivo
```

---

## âš™ï¸ Requisitos

InstalaciÃ³n de dependencias necesarias:

```bash
pip install -r requirements.txt
```

Contenido tÃ­pico del `requirements.txt`:

```
opencv-python
mediapipe
tensorflow
numpy
scikit-learn
matplotlib
jupyter
```

---

## ğŸš€ Instrucciones de uso

### 1. Recolectar datos

EjecutÃ¡ el siguiente script:

```bash
python record-dataset.py
```

PresionÃ¡:
- `0` para Piedra
- `1` para Papel
- `2` para Tijeras
- `ESC` para salir

> Las imÃ¡genes se guardan en la carpeta `dataset/` segÃºn la clase y se genera el archivo `.npy` con los datos.

---

### 2. Entrenar el modelo

```bash
python train-gesture-classifier.py
```

Este script:
- Escala los datos
- Codifica las etiquetas en formato one-hot
- Entrena una red neuronal
- Guarda el modelo y el escalador

---

### 3. ClasificaciÃ³n en tiempo real

```bash
python rock-paper-scissors.py
```

- Muestra la predicciÃ³n del gesto en la pantalla.
- Si presionÃ¡s la **barra espaciadora**, se guarda una captura en la carpeta `capturas/`.
- PresionÃ¡ **ESC** para salir.

---

## ğŸ“¦ Sobre el dataset

La carpeta `dataset/` fue comprimida como `dataset.rar` para poder subirla a GitHub, ya que contiene muchas imÃ¡genes.  
DescomprimÃ­ el archivo antes de entrenar el modelo para que `train-gesture-classifier.py` funcione correctamente.

---

## âš ï¸ Nota tÃ©cnica

Durante el desarrollo del proyecto hubo varios problemas relacionados con la instalaciÃ³n de librerÃ­as, especialmente con **MediaPipe** y **TensorFlow**.  
DespuÃ©s de probar diferentes configuraciones, se resolvieron los conflictos utilizando **Python 3.11.9**, que fue compatible con todas las dependencias sin errores de instalaciÃ³n ni ejecuciÃ³n.

> ğŸ’¡ RecomendaciÃ³n: si encontrÃ¡s errores al instalar las librerÃ­as, probÃ¡ crear un entorno virtual con Python 3.11.9.

