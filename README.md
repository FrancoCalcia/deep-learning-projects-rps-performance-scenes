# ‚úã Rock, Paper, Scissors - Clasificador de gestos con MediaPipe + Keras

Este proyecto permite capturar gestos desde la c√°mara web, entrenar un modelo de clasificaci√≥n y luego predecir en tiempo real los gestos de **Piedra**, **Papel** y **Tijeras**.

Se usa **MediaPipe** para detectar los puntos clave de la mano, y una **red neuronal entrenada con Keras** para clasificar el gesto.

---

## üìÅ Estructura del proyecto

```
rock-paper-scissors/
‚îú‚îÄ‚îÄ capturas/                      # Carpeta para im√°genes guardadas durante la predicci√≥n
‚îú‚îÄ‚îÄ dataset.rar                    # üì¶ Dataset comprimido (ver nota abajo)
‚îú‚îÄ‚îÄ record-dataset.py             # Script para grabar gestos y construir el dataset
‚îú‚îÄ‚îÄ train-gesture-classifier.py   # Script para entrenar la red neuronal
‚îú‚îÄ‚îÄ rock-paper-scissors.py        # Script para predecir el gesto en tiempo real
‚îú‚îÄ‚îÄ rps_dataset.npy               # Coordenadas x,y de cada gesto
‚îú‚îÄ‚îÄ rps_labels.npy                # Etiquetas correspondientes a los gestos
‚îú‚îÄ‚îÄ rps_model.h5                  # Modelo entrenado guardado
‚îú‚îÄ‚îÄ rps_scaler_mean.npy           # Media del escalador
‚îú‚îÄ‚îÄ rps_scaler_scale.npy          # Escala del escalador
‚îú‚îÄ‚îÄ requirements.txt              # Dependencias necesarias
‚îî‚îÄ‚îÄ README.md                     # Este archivo
```

---

## ‚öôÔ∏è Requisitos

Instalaci√≥n de dependencias necesarias:

```bash
pip install -r requirements.txt
```

Contenido t√≠pico del `requirements.txt`:

```
opencv-python
mediapipe
tensorflow
numpy
scikit-learn
matplotlib
jupyter
```

---

## üöÄ Instrucciones de uso

### 1. Recolectar datos

Ejecut√° el siguiente script:

```bash
python record-dataset.py
```

Presion√°:
- `0` para Piedra
- `1` para Papel
- `2` para Tijeras
- `ESC` para salir

> Las im√°genes se guardan en la carpeta `dataset/` seg√∫n la clase y se genera el archivo `.npy` con los datos.

---

### 2. Entrenar el modelo

```bash
python train-gesture-classifier.py
```

Este script:
- Escala los datos
- Codifica las etiquetas en formato one-hot
- Entrena una red neuronal
- Guarda el modelo y el escalador

---

### 3. Clasificaci√≥n en tiempo real

```bash
python rock-paper-scissors.py
```

- Muestra la predicci√≥n del gesto en la pantalla.
- Si presion√°s la **barra espaciadora**, se guarda una captura en la carpeta `capturas/`.
- Presion√° **ESC** para salir.

---

## üì¶ Sobre el dataset

La carpeta `dataset/` fue comprimida como `dataset.rar` para poder subirla a GitHub, ya que contiene muchas im√°genes.  
Descomprim√≠ el archivo antes de entrenar el modelo para que `train-gesture-classifier.py` funcione correctamente.
